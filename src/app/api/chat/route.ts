import { query, SDKUserMessage, type Options } from "@anthropic-ai/claude-code";
import type {
  ContentBlockParam,
  ImageBlockParam,
  TextBlockParam,
} from "@anthropic-ai/sdk/resources/messages/messages";
import {
  createUIMessageStream,
  createUIMessageStreamResponse,
  type UIMessage,
} from "ai";

export const maxDuration = 60000; // 60 seconds

function buildPromptFromContentBlocks(
  blocks: ContentBlockParam[]
): string | AsyncIterable<SDKUserMessage> {
  if (blocks.length === 1 && blocks[0].type === "text") {
    return blocks[0].text;
  }

  const messages: SDKUserMessage[] = blocks
    .filter((block) => block.type === "text" || block.type === "image")
    .map((block) => {
      if (block.type === "text") {
        return {
          type: "user",
          message: {
            role: "user",
            content: [{ type: "text", text: block.text }],
          },
          parent_tool_use_id: null,
        } as SDKUserMessage;
      }
      // Handle image blocks
      return {
        type: "user",
        message: {
          role: "user",
          content: [block],
        },
        parent_tool_use_id: null,
      } as SDKUserMessage;
    });

  // Return the messages as an async iterable or handle appropriately
  return (async function* () {
    for (const message of messages) {
      yield message;
    }
  })();
}

export async function POST(req: Request) {
  const { messages }: { messages: UIMessage[] } = await req.json();

  // Get the last user message
  const lastMessage = messages[messages.length - 1];

  console.log("[chat/route] received message:", lastMessage);

  // Build prompt with support for images and text
  const contentBlocks: ContentBlockParam[] = [];

  for (const part of lastMessage.parts) {
    console.log("[chat/route] processing part:", part.type);

    if (part.type === "text") {
      const textBlock: TextBlockParam = {
        type: "text",
        text: part.text,
      };
      contentBlocks.push(textBlock);
    } else if (
      part.type === "file" &&
      (part.mediaType === "image/jpeg" ||
        part.mediaType === "image/png" ||
        part.mediaType === "image/gif" ||
        part.mediaType === "image/webp")
    ) {
      const imageBlock: ImageBlockParam = {
        type: "image",
        source: {
          type: "base64",
          media_type: part.mediaType || "image/jpeg",
          data: part.url,
        },
      };
      contentBlocks.push(imageBlock);
    }
  }

  console.log(
    "[chat/route] content blocks to send:",
    JSON.stringify(contentBlocks).slice(0, 200)
  );

  // For backward compatibility, if only text parts exist, use a simple string
  const prompt = buildPromptFromContentBlocks(contentBlocks);

  // Track session for conversation continuity
  const sessionId = messages.length > 1 ? "chat-session" : undefined;
  const continueSession = messages.length > 1;

  // Create the stream first
  const stream = createUIMessageStream({
    execute: async (options) => {
      const { writer } = options;

      const claudeOptions: Options = {
        appendSystemPrompt: `
          You are GenieOS, a chat assistant running in a Next.js application directory. You have root access to hardware (you are running in a macOS sandbox environment).

          You have access to all mcp servers via the @genieos/mcp binary

          Example:
          bunx @genieos/mcp @modelcontextprotocol/server-puppeteer -- puppeteer_screenshot shot.png | jq -r '.content[1].data'
          bunx @genieos/mcp @modelcontextprotocol/server-filesystem -a '~/Desktop' -- list_directory '~/Desktop'

          To read each mcp server tools, just run:
          bunx @genieos/mcp @modelcontextprotocol/server-puppeteer help
          `,

        permissionMode: "bypassPermissions",
      };

      // handle session continuation
      if (continueSession) {
        claudeOptions.continue = true;
      } else if (sessionId) {
        claudeOptions.resume = sessionId;
      }

      for await (const message of query({
        prompt: prompt,
        options: claudeOptions,
      })) {
        console.log("[chat/route] received message:", message.type);

        if (message.type === "assistant" && message.message?.content) {
          writer.write({
            type: "text-start",
            id: "0",
          });

          for (const part of message.message.content) {
            if (part.type === "text") {
              // Stream each text chunk as it arrives
              writer.write({
                type: "text-delta",
                delta: part.text,
                id: "0",
              });
            }
          }

          writer.write({
            type: "text-end",
            id: "0",
          });
        } else {
          // TODO: deal with user and system messages LATER.
          // writer.write({
          //   type: "text-start",
          //   id: "0",
          // });
          // if (message.type === "user") {
          //   writer.write({
          //     type: "text-delta",
          //     delta: message.message?.content?.[0]?.text || "no content",
          //     id: "0",
          //   });
          // }
          // if (message.type === "system") {
          //   writer.write({
          //     type: "text-delta",
          //     delta: message.cwd,
          //     id: "0",
          //   });
          // }
          // writer.write({
          //   type: "text-end",
          //   id: "0",
          // });
        }
      }

      console.log("[chat/route] stream complete");
    },
  });

  // Return the response
  return createUIMessageStreamResponse({
    stream: stream,
  });
}
